# ML/DL 필수 이론 및 구현코드


- ### Tensorflow 없이 Numpy로 Deep Learning 구현하기 :<br>
> **구현의 목적**
>1. ML/DL의 수식을 기반으로 직접 코딩이 가능한 수준의 수학적 지식 습득 <br>
>2. Numpy와 python의 coding 능력 향상 <br>
>3. 즉, Neural Network를 numpy 기반의 python class로 작성 가능한 실력함양<br> 
    (**Tensorflow 등 High-level API를 사용하지 않음**)

<br>

- ### Section 1 : ML / DNN: <br>

| Classic ML and DNN | Source Code | Contents |
|---|:---:|:---:|
| __K-NN__ | [Numpy](https://github.com/Deepstroy/resume/blob/master/Machine%20Learning%20Algorithm%20(KNN%2C%20Kmeans%2C%20DNN%2C%20CNN%2C%20RNN%2C%20etc...)/K-NN/KNN_numpy.ipynb) / [Tensorflow](https://github.com/Deepstroy/resume/blob/master/Machine%20Learning%20Algorithm%20(KNN%2C%20Kmeans%2C%20DNN%2C%20CNN%2C%20RNN%2C%20etc...)/K-NN/KNN_tensorflow.ipynb) ||
| **K-Means** | [Numpy](https://github.com/Deepstroy/resume/blob/master/Machine%20Learning%20Algorithm%20(KNN%2C%20Kmeans%2C%20DNN%2C%20CNN%2C%20RNN%2C%20etc...)/K-Means/K_means_numpy.ipynb) |  |
| **K-Median** | [Numpy](https://github.com/Deepstroy/resume/blob/master/Machine%20Learning%20Algorithm%20(KNN%2C%20Kmeans%2C%20DNN%2C%20CNN%2C%20RNN%2C%20etc...)/K-Median/K_Median_numpy.ipynb) |  |
| **Principle Component Analysis (PCA)** | [Numpy](https://github.com/Deepstroy/resume/blob/master/Machine%20Learning%20Algorithm%20(KNN%2C%20Kmeans%2C%20DNN%2C%20CNN%2C%20RNN%2C%20etc...)/Principle%20Component%20Analysis/Principle%20Component%20Analysis_numpy.ipynb) / [Tensorflow](https://github.com/Deepstroy/resume/blob/master/Machine%20Learning%20Algorithm%20(KNN%2C%20Kmeans%2C%20DNN%2C%20CNN%2C%20RNN%2C%20etc...)/Principle%20Component%20Analysis/Principle_Component_Analysis_tensorflow.ipynb) ||
| __Weight Initialization Methods in Neural Networks__ |  |  ||
| └─ Xavier initialization with logistic function | [Numpy](https://google.com) / [Tensorflow](https://google.com) ||
| └─ He initialization with ReLU function | [Numpy](https://google.com) / [Tensorflow](https://google.com) ||
| __Back Propagation__  | [Numpy](https://google.com) / [Tensorflow](https://google.com) ||
| __Optimal Parameter Search Methods__ |  |  ||
| └─ Grid Search | [Numpy](https://google.com) ||
| └─ Gradient Descent Optimizer | [Tensorflow](https://google.com) ||
| └─ Momentum Optimizer | [Tensorflow](https://google.com)  ||
| └─ Nesterov Momentum Optimizer ★ | [Tensorflow](https://google.com)  ||
| └─ RMSProp Optimizer | [Tensorflow](https://google.com)  ||
| └─ Adam Optimizer ★| [Tensorflow](https://google.com)  ||
| __Regression Methods__ |   |   | |
| └─ Linear Regression |   |   | |
| └─ Multivariate Linear Regression |  |  | |
| __Regularization__ |   |   | |
| └─ L1 Regularization |   |   | |
| └─ L2 Regularization |  |  | |
| └─ Dropout / Inverted Dropout |  |  |  |
| __Batch Normalization__ |   |   | |
| └─ Batch Normalizatoin Step by Step |   |   | |
| __Deep Neural Networks in numpy ★__ |  |  | |
| └─ for Regression | [Code Link](https://google.com) | [Code Link](https://google.com) | |
| └─ for Classification | [Code Link](https://google.com) | [Code Link](https://google.com) | |
| **Auto Encoder** |  | | |
| └─ Vanilla Auto Encoder | [Code Link](https://google.com) | [Code Link](https://google.com) | |
| └─ Sparse Auto Encoder | [Code Link](https://google.com) | [Code Link](https://google.com) | |
| └─ Denoising Auto Encoder | [Code Link](https://google.com) | [Code Link](https://google.com) | |
| etc (Jacobian, Hessian,...)  | Code Link | Code Link ||
<br>

- ### Section 2 : Convolution Neural Networks <br>
| CNN models | Numpy code | Tensorflow code | Contents |
|---|:---:|:---:|:---:|
| __Key Methodology__ | [Code Link](https://google.com) | [Code Link](https://google.com) | |
| __Vanilla CNN__ |  | [Code Link](https://google.com) | |
| __LeNet__ | [Code Link](https://google.com) | [Code Link](https://google.com) | |
| __VGGNet__ | [Code Link](https://google.com) | [Code Link](https://google.com) | |
| __ResNet__ | [Code Link](https://google.com) | [Code Link](https://google.com) | |
